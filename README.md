#COS 429: Project Milestone Report
##Description of the Problem
In class, we discussed the issue of rotations, and how models may not recognize that an image is the same image just when it’s flipped or rotated by 90 degrees. One of the proposed solutions to this problem is data augmentation and using random crops and scales applied to images. However, upon researching rotationally equivariant networks, we found a paper written by T. Cohen et. al. titled “Group Equivariant Convolutional Networks” that describes Group equivariant Convolutional Neural Networks (G-CNNs). They reduce sample complexity by exploiting symmetries and use G-convolutions, a variation of G-convolutions. The paper proposes that group convolutional layers are easy to use and can be implemented with negligible computational overhead for discrete groups generated by translations, reflections, and rotations.

Link to the paper

##Pointers to Related Course Topics
In “Training CNNs”, Slides 122-145, this issue is explicitly discussed. The proposed solution to making our model more robust to these transformations is to do random crops and scales, randomize contrast and brightness, etc. However, we believe that G-CNNs are a more robust method of creating a rotation- and flip model, and will test this hypothesis in this project.

##Plans for acquiring the necessary data/computational resources
To test whether G-CNNs are able to properly account for rotations and flips, we will augment the CIFAR_10 dataset by performing the following operations on individually randomly selected subsets:

Rotate the images by 90 degrees clockwise
Rotate the images by 90 degrees counter clockwise
Rotate the images by 180 degrees counterclockwise
Flip the images along the y = 0 axis
Flip the images along the x = 0 axis
Flip the images along the y = x axis
Flip the images along the y = -x axis

##Plans for quantitative and qualitative evaluation
We’ll know the paper is correct if our G-CNN model is able to perform with higher accuracy on our augmented dataset than a baseline model without rotation and flip invariant filters. We will also compare things such as training time, loss, average iteration time, depth of network, complexity of model, etc.

##Target outcome
The goal of this project is to see how implementing a G-CNN compares to implementing a standard convolutional neural network that does not account for rotations or flips. Both networks should output a testing accuracy, and whichever one has a higher accuracy is therefore a better network for augmented data.